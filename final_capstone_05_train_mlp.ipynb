{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 1.0.0\n",
      "pytorch 1.3.1\n"
     ]
    }
   ],
   "source": [
    "print('pandas', pd.__version__)\n",
    "print('pytorch', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  9 02:00:29 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      3%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('gs://amazon_bucket/train_numeric_dl.tsv', sep=' ', header=None, dtype=np.int32)\n",
    "eval_df = pd.read_csv('gs://amazon_bucket/eval_numeric.tsv', sep=' ', header=None, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>469</th>\n",
       "      <th>470</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3521059</td>\n",
       "      <td>1189115</td>\n",
       "      <td>4352091</td>\n",
       "      <td>4664800</td>\n",
       "      <td>2091395</td>\n",
       "      <td>475580</td>\n",
       "      <td>2055385</td>\n",
       "      <td>1267201</td>\n",
       "      <td>2832609</td>\n",
       "      <td>3754422</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4570507</td>\n",
       "      <td>390981</td>\n",
       "      <td>2964667</td>\n",
       "      <td>5205699</td>\n",
       "      <td>544392</td>\n",
       "      <td>2164037</td>\n",
       "      <td>2964667</td>\n",
       "      <td>4368892</td>\n",
       "      <td>4873022</td>\n",
       "      <td>2111775</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415758</td>\n",
       "      <td>362915</td>\n",
       "      <td>1054491</td>\n",
       "      <td>660717</td>\n",
       "      <td>3376710</td>\n",
       "      <td>4235417</td>\n",
       "      <td>572327</td>\n",
       "      <td>1552755</td>\n",
       "      <td>475580</td>\n",
       "      <td>2700358</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1735072</td>\n",
       "      <td>349092</td>\n",
       "      <td>4500667</td>\n",
       "      <td>4302042</td>\n",
       "      <td>5073616</td>\n",
       "      <td>349092</td>\n",
       "      <td>2111775</td>\n",
       "      <td>1033319</td>\n",
       "      <td>2090218</td>\n",
       "      <td>3611929</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3852213</td>\n",
       "      <td>3910364</td>\n",
       "      <td>127502</td>\n",
       "      <td>1267201</td>\n",
       "      <td>4525159</td>\n",
       "      <td>475580</td>\n",
       "      <td>2964667</td>\n",
       "      <td>2557625</td>\n",
       "      <td>390981</td>\n",
       "      <td>2964667</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2        3        4        5        6        7    \\\n",
       "0  3521059  1189115  4352091  4664800  2091395   475580  2055385  1267201   \n",
       "1  4570507   390981  2964667  5205699   544392  2164037  2964667  4368892   \n",
       "2   415758   362915  1054491   660717  3376710  4235417   572327  1552755   \n",
       "3  1735072   349092  4500667  4302042  5073616   349092  2111775  1033319   \n",
       "4  3852213  3910364   127502  1267201  4525159   475580  2964667  2557625   \n",
       "\n",
       "       8        9    ...      469      470      471      472      473  \\\n",
       "0  2832609  3754422  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "1  4873022  2111775  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "2   475580  2700358  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "3  2090218  3611929  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "4   390981  2964667  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "\n",
       "       474      475      476      477  478  \n",
       "0  5256337  5256337  5256337  5256337    5  \n",
       "1  5256337  5256337  5256337  5256337    5  \n",
       "2  5256337  5256337  5256337  5256337    5  \n",
       "3  5256337  5256337  5256337  5256337    5  \n",
       "4  5256337  5256337  5256337  5256337    5  \n",
       "\n",
       "[5 rows x 479 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(train_df.iloc[:, :-1].values, dtype=torch.long)\n",
    "X_eval_tensor = torch.tensor(eval_df.iloc[:, :-1].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(train_df.iloc[:, -1].values, dtype=torch.long)\n",
    "y_eval_tensor = torch.tensor(eval_df.iloc[:, -1].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>468</th>\n",
       "      <th>469</th>\n",
       "      <th>470</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3521059</td>\n",
       "      <td>1189115</td>\n",
       "      <td>4352091</td>\n",
       "      <td>4664800</td>\n",
       "      <td>2091395</td>\n",
       "      <td>475580</td>\n",
       "      <td>2055385</td>\n",
       "      <td>1267201</td>\n",
       "      <td>2832609</td>\n",
       "      <td>3754422</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4570507</td>\n",
       "      <td>390981</td>\n",
       "      <td>2964667</td>\n",
       "      <td>5205699</td>\n",
       "      <td>544392</td>\n",
       "      <td>2164037</td>\n",
       "      <td>2964667</td>\n",
       "      <td>4368892</td>\n",
       "      <td>4873022</td>\n",
       "      <td>2111775</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415758</td>\n",
       "      <td>362915</td>\n",
       "      <td>1054491</td>\n",
       "      <td>660717</td>\n",
       "      <td>3376710</td>\n",
       "      <td>4235417</td>\n",
       "      <td>572327</td>\n",
       "      <td>1552755</td>\n",
       "      <td>475580</td>\n",
       "      <td>2700358</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1735072</td>\n",
       "      <td>349092</td>\n",
       "      <td>4500667</td>\n",
       "      <td>4302042</td>\n",
       "      <td>5073616</td>\n",
       "      <td>349092</td>\n",
       "      <td>2111775</td>\n",
       "      <td>1033319</td>\n",
       "      <td>2090218</td>\n",
       "      <td>3611929</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3852213</td>\n",
       "      <td>3910364</td>\n",
       "      <td>127502</td>\n",
       "      <td>1267201</td>\n",
       "      <td>4525159</td>\n",
       "      <td>475580</td>\n",
       "      <td>2964667</td>\n",
       "      <td>2557625</td>\n",
       "      <td>390981</td>\n",
       "      <td>2964667</td>\n",
       "      <td>...</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "      <td>5256337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2        3        4        5        6        7    \\\n",
       "0  3521059  1189115  4352091  4664800  2091395   475580  2055385  1267201   \n",
       "1  4570507   390981  2964667  5205699   544392  2164037  2964667  4368892   \n",
       "2   415758   362915  1054491   660717  3376710  4235417   572327  1552755   \n",
       "3  1735072   349092  4500667  4302042  5073616   349092  2111775  1033319   \n",
       "4  3852213  3910364   127502  1267201  4525159   475580  2964667  2557625   \n",
       "\n",
       "       8        9    ...      468      469      470      471      472  \\\n",
       "0  2832609  3754422  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "1  4873022  2111775  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "2   475580  2700358  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "3  2090218  3611929  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "4   390981  2964667  ...  5256337  5256337  5256337  5256337  5256337   \n",
       "\n",
       "       473      474      475      476      477  \n",
       "0  5256337  5256337  5256337  5256337  5256337  \n",
       "1  5256337  5256337  5256337  5256337  5256337  \n",
       "2  5256337  5256337  5256337  5256337  5256337  \n",
       "3  5256337  5256337  5256337  5256337  5256337  \n",
       "4  5256337  5256337  5256337  5256337  5256337  \n",
       "\n",
       "[5 rows x 478 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:5, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1290927, 478])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eval_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor -= 1  # To aid with cross-entropy loss.\n",
    "y_eval_tensor -= 1\n",
    "assert y_train_tensor.max() == 4 and y_train_tensor.min() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "n_classes = set(y_train_tensor.tolist())\n",
    "print(len(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = F.one_hot(y_train_tensor.view(-1, 1), num_classes=len(n_classes))\n",
    "y_eval_tensor = F.one_hot(y_eval_tensor.view(-1, 1), num_classes=len(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_true):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_true).sum().item()\n",
    "    return torch.tensor(n_correct / y_pred_indices.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weight(series):\n",
    "    counts = Counter(series)\n",
    "    weights = {k: (v / len(series)) for k, v in counts.items()}\n",
    "    weight_tuples = sorted([(k, v) for k, v in weights.items()])\n",
    "    sorted_weights = [weight for _, weight in weight_tuples]\n",
    "    return torch.tensor(sorted_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding_index(padding_value, vocab):\n",
    "    \"\"\"Takes a string and returns an int which corresponds to the padding index.\"\"\"\n",
    "    return vocab[padding_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(file_path):\n",
    "    \"\"\"Loads a json file and converts it to a dictionary.\"\"\"\n",
    "    with open(file_path, 'r') as d:\n",
    "        out = json.load(d)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket('amazon_bucket')\n",
    "blob = bucket.get_blob('word_to_index.json')\n",
    "json_data = blob.download_to_filename('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json') as jd:\n",
    "    word_to_index = json.load(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = compute_class_weight(y_train_tensor.squeeze().max(dim=1).indices.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_index = get_padding_index('<pad>', word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_torch = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "eval_torch = torch.utils.data.TensorDataset(X_eval_tensor, y_eval_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModelMLP(pl.LightningModule):\n",
    "    def __init__(self, vocab_size=len(word_to_index.keys()), embedding_size=60,\n",
    "               dropout=0.25, num_classes=len(weights),\n",
    "               h1=512, h2=256, h3=128, h4=32):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                       embedding_dim=embedding_size,\n",
    "                                       padding_idx = padding_index,\n",
    "                                       sparse=False)\n",
    "        self.linear1 = nn.Linear(in_features=embedding_size, out_features=h1)\n",
    "        self.linear2 = nn.Linear(in_features=h1, out_features=h2)\n",
    "        self.linear3 = nn.Linear(in_features=h2, out_features=h3)\n",
    "        self.linear4 = nn.Linear(in_features=h3, out_features=h4)\n",
    "        self.out = nn.Linear(in_features=h4, out_features=num_classes)\n",
    "        self.dropout_p = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(self.embeddings(x)))\n",
    "        x = F.dropout(x, p=self.dropout_p)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=self.dropout_p)\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = F.dropout(x, p=self.dropout_p)\n",
    "        x = F.relu(self.linear4(x))\n",
    "        x = F.dropout(x, p=self.dropout_p)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(train_torch, batch_size=512,\n",
    "                                           shuffle=True, pin_memory=True,\n",
    "                                           drop_last=True)\n",
    "        \n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(eval_torch, batch_size=512,\n",
    "                                           shuffle=True, pin_memory=True,\n",
    "                                           drop_last=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        acc_t = compute_accuracy(y_pred, y)\n",
    "        loss = F.cross_entropy(y_pred, y.squeeze())\n",
    "        self.logger.experiment.log(\n",
    "            {'loss': loss.item(),\n",
    "             'train_acc': acc_t.item(),\n",
    "             'batch_nb': batch_nb})\n",
    "        return {'loss': F.cross_entropy(y_pred, y.squeeze()), 'train_acc': acc_t}\n",
    "\n",
    "#     def training_end(self, outputs):\n",
    "#         average_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "#         average_accuracy = torch.stack([x['train_acc'] for x in outputs]).mean()\n",
    "#         return {'mean_train_loss': average_loss,\n",
    "#                 'mean_train_accuracy': average_accuracy}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = F.cross_entropy(y_pred, y.squeeze())\n",
    "        acc_t = compute_accuracy(y_pred, y)\n",
    "        self.logger.experiment.log(\n",
    "            {'val_loss': loss.item(),\n",
    "             'val_acc': acc_t.item(),\n",
    "             'batch_nb': batch_nb})\n",
    "        return {'val_loss': loss, 'val_acc': acc_t}\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        average_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        average_accuracy = \\\n",
    "            torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        return {'mean_val_loss': average_loss, \n",
    "                'mean_val_accuracy': average_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=f'{os.getcwd()}/mlp_model', save_best_only=True, verbose=True,\n",
    "    monitor='mean_val_loss', mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = pl.callbacks.EarlyStopping(\n",
    "    monitor='mean_val_loss', min_delta=0.0005, patience=3, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl.logging.TestTubeLogger(\n",
    "    save_dir=f'{os.getcwd()}/train_logs/mlp_model', name='mlp_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(logger=logger, checkpoint_callback=checkpoint_callback,\n",
    "                     max_nb_epochs=50, min_nb_epochs=10, gpus=1, \n",
    "                     early_stop_callback=early_stopping_callback,\n",
    "                     fast_dev_run=False, use_amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextModelMLP(\n",
       "  (embeddings): Embedding(5490692, 60, padding_idx=5256337)\n",
       "  (linear1): Linear(in_features=60, out_features=512, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (linear3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear4): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (out): Linear(in_features=32, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextModelMLP()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
