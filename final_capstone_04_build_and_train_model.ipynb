{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_capstone_04_build_and_train_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serfsup/thinkful-final-capstone/blob/master/final_capstone_04_build_and_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RFDnjDCACFj",
        "colab_type": "code",
        "outputId": "44c770bc-1702-4a28-fb6e-7f51f8e850a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhbgtqwB6D3l",
        "colab_type": "code",
        "outputId": "b76a2df2-0b16-4700-ba3b-8eb2570428ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'drive/My Drive/Colab Datasets'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJTXa9Uz4BVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch_lightning==0.5.2 -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_vsN-OrAp8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhuY7L3l3l1g",
        "colab_type": "code",
        "outputId": "d645ba2e-d301-40b6-9388-c2ca49f9ada8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('Pandas:', pd.__version__)\n",
        "print('PyTorch:', torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pandas: 0.25.3\n",
            "PyTorch: 1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwlvC7IleIQB",
        "colab_type": "code",
        "outputId": "8ced768b-847a-4d58-9bc5-21092b0d8bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip list | grep pytorch-lightning"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pytorch-lightning        0.5.2      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z9E_aIk8VEV",
        "colab_type": "code",
        "outputId": "083c1dc4-a250-4416-d1c2-6260e54c7256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "train_target = pd.read_csv('./train_clean.tsv', sep='\\t', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozu7TaPj9QFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_target = pd.read_csv('./eval_clean.tsv', sep='\\t', index_col=0,\n",
        "                          error_bad_lines=False, engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tld9OdqOJTJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_target = train_target.loc[:, 'target'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_T21ex0MJ0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_target = eval_target.loc[:, 'target'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEinwHTANN2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subtracting 1 to have a zero class to aid in cross-entropy loss function.\n",
        "train_target -= 1\n",
        "eval_target -= 1\n",
        "assert train_target.max() == 4 and train_target.min() == 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JspMXRtPNs7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(y_pred, y_true):\n",
        "  _, y_pred_indices = y_pred.max(dim=1)\n",
        "  n_correct = torch.eq(y_pred_indices, y_true).sum()\n",
        "  return torch.tensor(\n",
        "      n_correct / len(y_pred_indices) * 100, dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzB4UH_TBWFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_learning_rate(optimizer):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    return param_group['lr']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PgOAuQUBp-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_class_weights(arr):\n",
        "  counts = Counter(arr)\n",
        "  weights = {k: (v / len(arr)) for k, v in counts.items()}\n",
        "  weight_tuples = sorted([(k, v) for k, v in weights.items()])\n",
        "  sorted_weights = [weight for _, weight in weight_tuples]\n",
        "  return torch.tensor(sorted_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os-p_DckC9MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_vocab(file_path):\n",
        "  \"\"\"Loads a json file and converts it to a dictionary.\"\"\"\n",
        "  with open(file_path, 'r') as d:\n",
        "    return json.load(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXhW1NCFDoj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_padding_index(padding_value, vocab):\n",
        "  \"\"\"Takes a string and returns an int that corresponds to the padding index.\"\"\"\n",
        "  return vocab[padding_value]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC5Qfdr-ECtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, chunksize, n_samples):\n",
        "        self.path = path\n",
        "        self.chunksize = chunksize\n",
        "        self.length = int(n_samples / self.chunksize)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = next(pd.read_csv(self.path, skiprows=(index * self.chunksize), \n",
        "                                chunksize=self.chunksize, sep=' ', header=None,\n",
        "                                engine='python')) \n",
        "        y = data.iloc[:, -1:].values\n",
        "        y -= 1  # to aid with cross-entropy loss\n",
        "        y = torch.tensor(y, dtype=torch.int64)\n",
        "        y = F.one_hot(y, num_classes=5)\n",
        "        x = data.iloc[:, :-1].values\n",
        "        x = torch.tensor(x, dtype=torch.int64)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfNqfmm5ILph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = load_vocab('word_to_index.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbwvHxIoIj_h",
        "colab_type": "code",
        "outputId": "f4d75513-7fae-4990-e2bb-9b03e8849c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnaNmaXeJEn_",
        "colab_type": "code",
        "outputId": "25eff564-f711-40b3-c439-b018499e31e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Dec 12 16:39:24 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.36       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    28W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk9JxZITJXTQ",
        "colab_type": "code",
        "outputId": "b2adc650-b86b-4743-d7e9-ed75d8a11b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights = compute_class_weights(train_target).to(device)\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0568, 0.0391, 0.0767, 0.1804, 0.6469], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZE1MeArJwws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padding_index = get_padding_index('<pad>', vocab)\n",
        "assert padding_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB3RsbgUP6Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TextDataset('train_numeric.tsv', 16, 6024321)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsQb7vV_P6NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_dataset = TextDataset('eval_numeric.tsv', 16, 1290927)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kttha3nIKKUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextModelMLP(pl.LightningModule):\n",
        "    def __init__(self, vocab_size=len(vocab.keys()), embedding_size=100,\n",
        "               dropout=0.25, num_classes=len(weights),\n",
        "               h1=512, h2=256, h3=128, h4=32):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                       embedding_dim=embedding_size,\n",
        "                                       padding_idx = padding_index,\n",
        "                                       sparse=False)\n",
        "        self.linear1 = nn.Linear(in_features=embedding_size, out_features=h1)\n",
        "        self.linear2 = nn.Linear(in_features=h1, out_features=h2)\n",
        "        self.linear3 = nn.Linear(in_features=h2, out_features=h3)\n",
        "        self.linear4 = nn.Linear(in_features=h3, out_features=h4)\n",
        "        self.out = nn.Linear(in_features=h4, out_features=num_classes)\n",
        "        self.dropout_p = dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(self.embeddings(x)))\n",
        "        x = F.dropout(x, p=self.dropout_p)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.dropout(x, p=self.dropout_p)\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = F.dropout(x, p=self.dropout_p)\n",
        "        x = F.relu(self.linear4(x))\n",
        "        x = F.dropout(x, p=self.dropout_p)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "    @pl.data_loader\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(train_dataset, batch_size=64,\n",
        "                                           shuffle=False, pin_memory=True,\n",
        "                                           drop_last=True, num_workers=4)\n",
        "        \n",
        "    @pl.data_loader\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(eval_dataset, batch_size=64,\n",
        "                                           shuffle=False, pin_memory=True,\n",
        "                                           drop_last=True, num_workers=4)\n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-5)\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        x = x.view(1024, 478)\n",
        "        y = y.view(1024, 5)\n",
        "        y_pred = self.forward(x)\n",
        "        acc_t = compute_accuracy(y_pred, y)\n",
        "        loss = F.cross_entropy(y_pred, y)\n",
        "        self.logger.experiment.log(\n",
        "            {'loss': loss.item(),\n",
        "             'train_acc': acc_t.item(),\n",
        "             'batch_nb': batch_nb})\n",
        "        return {'loss': loss, 'train_acc': acc_t}\n",
        "\n",
        "    def training_end(self, outputs):\n",
        "        average_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "        average_accuracy = torch.stack([x['train_acc'] for x in outputs]).mean()\n",
        "        return {'mean_train_loss': average_loss,\n",
        "                'mean_train_accuracy': average_accuracy}\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        x = x.view(1024, 478)\n",
        "        y = y.view(1024, 5)\n",
        "        y_pred = self.forward(x)\n",
        "        loss = F.cross_entropy(y_pred, y)\n",
        "        acc_t = compute_accuracy(y_pred, y)\n",
        "        self.logger.experiment.log(\n",
        "            {'val_loss': loss.item(),\n",
        "             'val_acc': acc_t.item(),\n",
        "             'batch_nb': batch_nb})\n",
        "        return {'val_loss': loss, 'val_acc': acc_t}\n",
        "\n",
        "    def validation_end(self, outputs):\n",
        "        average_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        average_accuracy = \\\n",
        "            torch.stack([x['val_acc'] for x in outputs]).mean()\n",
        "        return {'mean_val_loss': average_loss, \n",
        "                'mean_val_accuracy': average_accuracy}\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaNnXMlNYK6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=f'{os.getcwd()}/mlp_model', save_best_only=True, verbose=True,\n",
        "    monitor='mean_val_loss', mode='min'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh-VOP1DYK0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping_callback = pl.callbacks.EarlyStopping(\n",
        "    monitor='mean_val_loss', min_delta=0.0005, patience=3, verbose=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh7jYUlqYKtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger = pl.logging.TestTubeLogger(\n",
        "    save_dir=f'{os.getcwd()}/train_logs/mlp_model', name='mlp_model'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBmCeIJ8YKkc",
        "colab_type": "code",
        "outputId": "03de5424-cece-439c-c2c0-bbc3a95151d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "trainer = pl.Trainer(logger=logger, checkpoint_callback=checkpoint_callback,\n",
        "                     max_nb_epochs=25, min_nb_epochs=10, gpus=1, \n",
        "                     early_stop_callback=early_stopping_callback,\n",
        "                     fast_dev_run=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpu available: True, used: True\n",
            "VISIBLE GPUS: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIu6zHjYYKbF",
        "colab_type": "code",
        "outputId": "43b109ae-d94a-4677-b6bc-776e7beefdac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "model = TextModelMLP()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextModelMLP(\n",
              "  (embeddings): Embedding(4516760, 100, padding_idx=4337549)\n",
              "  (linear1): Linear(in_features=100, out_features=512, bias=True)\n",
              "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (linear3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (linear4): Linear(in_features=128, out_features=32, bias=True)\n",
              "  (out): Linear(in_features=32, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snq_6AUjYKL2",
        "colab_type": "code",
        "outputId": "d34af4e9-ccdd-4b7b-9157-1d86c00b2a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "         Name       Type Params\n",
            "0  embeddings  Embedding  451 M\n",
            "1     linear1     Linear   51 K\n",
            "2     linear2     Linear  131 K\n",
            "3     linear3     Linear   32 K\n",
            "4     linear4     Linear    4 K\n",
            "5         out     Linear  165  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "201it [9:37:42, 305.13s/it, batch_nb=200, epoch=0, gpu=0, loss=6.099, v_nb=20]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}